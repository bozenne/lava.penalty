% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Penalty_estimate.R
\name{estimate.plvm}
\alias{estimate}
\alias{estimate.plvm}
\title{Penalized lvm model}
\usage{
\method{estimate}{plvm}(x, data, lambda1 = NULL, lambda2 = NULL,
  lambdaN = NULL, adaptive = FALSE, control = list(),
  estimator = "penalized", regularizationPath = FALSE,
  resolution_lambda1 = lava.options()$EPSODE$resolution_lambda1,
  increasing = TRUE, reversible = FALSE, stopLambda = NULL,
  stopParam = NULL, exportAllPath = FALSE,
  fit = lava.options()$calcLambda$fit, fixSigma = FALSE, ...)
}
\arguments{
\item{x}{a penalized lvm model}

\item{data}{a data.frame containing the data}

\item{lambda1}{lasso penalization parameter}

\item{lambda2}{ridge penalization parameter}

\item{lambdaN}{Nuclear norm penalization parameter}

\item{adaptive}{should the coefficient of the adaptive lasso be returned instead of the coefficient of the lasso}

\item{control}{control/optimization parameters}

\item{estimator}{the method used to compute the likelihood, gradient and hessian.}

\item{regularizationPath}{should the regularization path be computed. If so the argument lambda1 is ignored but not lambda2.}

\item{resolution_lambda1, increasing, stopLambda, stopParam}{arguments for the EPSODE function (see \code{EPSODE})}

\item{fit}{criterion to decide of the optimal model to retain among the penalized models.}

\item{fixSigma}{should the variance parameter be fixed at 1 ? Only works for regression models. [temporary]}

\item{...}{additional arguments to be passed to lava:::estimate.lvm}

\item{method.proxGrad, step, BT.n, BT.eta, force.descent}{arguments for the proximal gradient algorithm (see \code{proxGrad})}
}
\value{
a plvmfit object
}
\description{
Estimate a penalized lvm model
}
\details{
Available estimators are:
\itemize{
 \item{"penalized"}{ the hessian is computed as E[t(S) S]}
 \item{"numDeriveSimple"}{ the hessian is computed using numerical derivatives}
 \item{"numDeriveRichardson"}{ the hessian is computed using numerical derivatives (Richardson method)}
 \item{"explicit"}{ the hessian is computed using an explicit formula}
}
}
\examples{
# library(ggplot2)
# library(lava)
library(lava.penalty)

EPSODE_options <- lava.options()$EPSODE
EPSODE_options$resolution_lambda1 <- c(1e-10,1)
lava.options(EPSODE = EPSODE_options)

####> linear regression ####
set.seed(10)
n <- 300
formula.lvm <- as.formula(paste0("Y~",paste(paste0("X",1:12), collapse = "+")))
mSim <- lvm(formula.lvm)
df.data <- sim(mSim,n)

lvm.model <- lvm(formula.lvm)
plvm.model <- penalize(lvm.model)

#### lasso penalty

## regularization path
path1F <- estimate(plvm.model,  data = df.data, regularizationPath = TRUE, fixSigma = TRUE)

# backward
path1B <- estimate(plvm.model,  data = df.data, regularizationPath = TRUE,
                   increasing = FALSE, fixSigma = TRUE)

getPath(path1B)

plot(path1B)
plot(path1B, type = "path")

## proxGrad
pfit <- estimate(plvm.model,  data = df.data,
                 lambda1 = getPath(path1B, names = "lambda1.abs")[6,1],
                 control = list(constrain = TRUE), fixSigma = TRUE)
pfit

#### ridge penalty
pfit <- estimate(plvm.model,  data = df.data, lambda2 = 10, control = list(constrain = TRUE))
pfit

#### elastic net penalty
pfit <- estimate(plvm.model,  data = df.data, lambda1 = 100, lambda2 = 10, control = list(constrain = TRUE))
pfit

#### group lasso penalty
plvm.model <- penalize(lvm.model, value = paste0("Y~X",1:4), group = 1)
plvm.model <- penalize(plvm.model, value = paste0("Y~X",5:9), group = 2)

pfit <- estimate(plvm.model,  data = df.data, lambda1 = 80, control = list(constrain = TRUE), fixSigma = TRUE)
pfit

#### nuclear norm penalty
n.obs <- 100
res <- simForm(n.obs, xmax = 25, ymax = 25, radius = 5)
coords <- res$coords
n.coord <- nrow(coords)
betaI <- as.vector(res$X)
X <- matrix(rnorm(n.obs*n.coord), nrow = n.obs, ncol = n.coord)
Xnames <- paste0("X",1:n.coord)

n.confounder <- 5
gamma <- rep(1, n.confounder)
Z <- matrix(rnorm(n.obs*n.confounder), nrow = n.obs, ncol = n.confounder)
Znames <- paste0("Z",1:n.confounder)

Y <- Z \%*\% gamma + X \%*\% betaI + rnorm(n.obs)
formula.lvm <- as.formula( paste0("Y~", paste0("X",1:n.coord, collapse = "+") ) )

dt.data <- data.table(Y=Y,data.frame(Z),data.frame(X))
names(dt.data) <- c("Y",Znames,Xnames)
dt.data[, (names(dt.data)) := lapply(.SD,scale), .SDcols = names(dt.data)]

##
lvm.image <- lvm(as.formula(paste0("Y~",paste(Znames, collapse = "+"))))
plvm.image <- lvm.image
penalizeNuclear(plvm.image, coords = coords) <- as.formula(paste0("Y~",paste0(Xnames,collapse = "+")))

for(lambda in c(1e0,1e1,1e2)){
  elvm.Path <- estimate(plvm.image,  data = dt.data, lambdaN = lambda, 
                        control = list(iter.max = 100))
  B.LS <- matrix(attr(elvm.Path$opt$message,"par")[paste0("Y~",Xnames)],
                 nrow = NROW(res$X), ncol = NCOL(res$X), byrow = TRUE)
  fields:::image.plot(B.LS)
}


####> Latent variable model ####

set.seed(10)
n <- 300
mSim <- lvm(list(Y1 ~ eta + X1, Y2 ~ eta, Y3 ~ eta + X2))
latent(mSim) <- ~eta
regression(mSim) <- eta~Z1
covariance(mSim) <- Y1~Y2

df.data <- sim(mSim,n)


#### partial lasso penalty
m <- mSim
regression(m) <- Y2~X1+X2
pm <- penalize(m, c("Y2~X1","Y2~X2","Y3~X2"))

## regularization path
path.lvm <- estimate(pm, df.data, regularizationPath = TRUE, stopParam = 1, increasing = FALSE)

pathLVM <- calcLambda(model = pm, data.fit = df.data, seq_lambda1 = seq(0,300, length.out = 5))
plot(pathLVM)
plot(pathLVM, type = "path")
# lava:::estimate.lvm(pm, scale(df.data))

## use the default proximal gradient (ISTA)
proxGrad_options <- lava.options()$proxGrad
proxGrad_options$method <- "ISTA"
lava.options(proxGrad = proxGrad_options)

e <- estimate(pm, df.data, lambda1 = 0, control = list(constrain = TRUE))

## change the proximal gradient method to monotone FISTA
proxGrad_options <- lava.options()$proxGrad
proxGrad_options$method <- "mFISTA"
lava.options(proxGrad = proxGrad_options)

e <- estimate(pm, df.data, lambda1 = 0, control = list(constrain = TRUE))


e <- estimate(pm, df.data, lambda1 = 2e1, control = list(constrain = TRUE))




}
\references{
Zhou 2014 - A generic Path Algorithm for Regularized Statistical Estimation \cr
Park 2007 - L1-regularization path algorithm for GLM
}

